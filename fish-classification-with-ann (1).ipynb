{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**IMPORTING THE MODULS**","metadata":{}},{"cell_type":"markdown","source":"Here we are adding the necessary libraries for the artificial intelligence to function properly.\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport struct\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:13.299937Z","iopub.execute_input":"2024-10-24T14:35:13.300667Z","iopub.status.idle":"2024-10-24T14:35:28.357116Z","shell.execute_reply.started":"2024-10-24T14:35:13.300628Z","shell.execute_reply":"2024-10-24T14:35:28.356268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOADİNG DATA**","metadata":{}},{"cell_type":"markdown","source":"Creating a data frame with the image path and label.\n\nThis code finds the .png files located in a directory and adds the full path of each file along with its directory name (as a label) to a DataFrame. We will use this data structure later for analysis or model training.\n\n\n\r\n\r\n","metadata":{}},{"cell_type":"code","source":"dir = '../input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\nlabel = []\npath = []                                                            \nfor dirname, _,filenames in os.walk(dir):                           \n    for filename in filenames:\n\n        if os.path.splitext(filename)[1]=='.png':                     \n            if dirname.split()[-1]!='GT':                              \n                label.append(os.path.split(dirname)[1])              \n                path.append(os.path.join(dirname,filename))          \ndata = pd.DataFrame(columns=['path','label'])                         \ndata['path']=path\ndata['label']=label                                                     ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:28.359078Z","iopub.execute_input":"2024-10-24T14:35:28.359729Z","iopub.status.idle":"2024-10-24T14:35:30.078971Z","shell.execute_reply.started":"2024-10-24T14:35:28.359682Z","shell.execute_reply":"2024-10-24T14:35:30.077980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CONTROLLİNG THE DATA**","metadata":{}},{"cell_type":"markdown","source":"This way, you can see whether the path and label columns of the data are filled in correctly.\n\n","metadata":{}},{"cell_type":"code","source":"data.head()  \n#This command is used to print the first few rows (by default, 5 rows) of a Pandas DataFrame to the screen. ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.080537Z","iopub.execute_input":"2024-10-24T14:35:30.081177Z","iopub.status.idle":"2024-10-24T14:35:30.095747Z","shell.execute_reply.started":"2024-10-24T14:35:30.081142Z","shell.execute_reply":"2024-10-24T14:35:30.094623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data.info() command provides general and quick information about your dataset, making it very useful for checking whether there are any missing values, whether the data types are correct, and the memory usage.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.097853Z","iopub.execute_input":"2024-10-24T14:35:30.098490Z","iopub.status.idle":"2024-10-24T14:35:30.125514Z","shell.execute_reply.started":"2024-10-24T14:35:30.098456Z","shell.execute_reply":"2024-10-24T14:35:30.124180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It shows how many of each fish species there are.\n\n","metadata":{}},{"cell_type":"code","source":"data['label']=data['label'].astype('category') \ndata['label'].value_counts(ascending=True)   ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.126735Z","iopub.execute_input":"2024-10-24T14:35:30.127123Z","iopub.status.idle":"2024-10-24T14:35:30.145753Z","shell.execute_reply.started":"2024-10-24T14:35:30.127080Z","shell.execute_reply":"2024-10-24T14:35:30.144594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.countplot(y='label', data=data)\nplt.title('Types Of Fishes')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.147230Z","iopub.execute_input":"2024-10-24T14:35:30.147880Z","iopub.status.idle":"2024-10-24T14:35:30.491540Z","shell.execute_reply.started":"2024-10-24T14:35:30.147819Z","shell.execute_reply":"2024-10-24T14:35:30.490613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA ANALYSIS**","metadata":{}},{"cell_type":"code","source":"data['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.492878Z","iopub.execute_input":"2024-10-24T14:35:30.493215Z","iopub.status.idle":"2024-10-24T14:35:30.501817Z","shell.execute_reply.started":"2024-10-24T14:35:30.493181Z","shell.execute_reply":"2024-10-24T14:35:30.500988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Displaying first 9 images of fishes","metadata":{}},{"cell_type":"code","source":"idx = 0\nplt.figure(figsize=(15,12)) \nfor unique_label in data['label'].unique():  \n    plt.subplot(3, 3, idx+1)\n    plt.imshow(plt.imread(data[data['label']==unique_label].iloc[0,0])) \n    plt.title(unique_label)\n    plt.axis('off')\n    idx+=1","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:30.503551Z","iopub.execute_input":"2024-10-24T14:35:30.503949Z","iopub.status.idle":"2024-10-24T14:35:32.809060Z","shell.execute_reply.started":"2024-10-24T14:35:30.503907Z","shell.execute_reply":"2024-10-24T14:35:32.808077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These codes display a sample image for each unique class in the DataFrame on a 3x3 grid. The loop selects one image from each class, displays it in the corresponding subplot, and adds the class name as the title.\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**TRAINING AND TEST SETS**","metadata":{}},{"cell_type":"markdown","source":"The following codes are used to split the dataset into a training set and a test set. The aim is to appropriately divide the data for model training and evaluation.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test=train_test_split(data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:32.810290Z","iopub.execute_input":"2024-10-24T14:35:32.810612Z","iopub.status.idle":"2024-10-24T14:35:32.819397Z","shell.execute_reply.started":"2024-10-24T14:35:32.810579Z","shell.execute_reply":"2024-10-24T14:35:32.818476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:32.823719Z","iopub.execute_input":"2024-10-24T14:35:32.824133Z","iopub.status.idle":"2024-10-24T14:35:32.833992Z","shell.execute_reply.started":"2024-10-24T14:35:32.824092Z","shell.execute_reply":"2024-10-24T14:35:32.832993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preparing the Image Dataset for Training, Validation, and Testing (with TensorFlow)**","metadata":{}},{"cell_type":"markdown","source":"This section is for preparing the dataset to be used in the deep learning model with Keras. The aim is to convert the images into a format suitable for the model, apply data augmentation, and create generators for the training/test sets.\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications        import ResNet50V2, MobileNetV2\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrainGen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.3)\ntestGen =ImageDataGenerator(preprocessing_function= preprocess_input)\nX_train_img = trainGen.flow_from_dataframe(dataframe=X_train, x_col='path', y_col='label',class_mode='categorical', subset='training', color_mode='rgb', batch_size=32)\nX_val_img = trainGen.flow_from_dataframe(dataframe=X_train, x_col='path', y_col='label',class_mode='categorical', subset='validation', color_mode='rgb', batch_size=32)\nX_test_img =testGen.flow_from_dataframe(dataframe=X_test, x_col='path', y_col='label',class_mode='categorical', color_mode='rgb', batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:32.835126Z","iopub.execute_input":"2024-10-24T14:35:32.835412Z","iopub.status.idle":"2024-10-24T14:35:37.366503Z","shell.execute_reply.started":"2024-10-24T14:35:32.835381Z","shell.execute_reply":"2024-10-24T14:35:37.365573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**IMAGE PLOTTING AFTER PREPROCESSING**","metadata":{}},{"cell_type":"markdown","source":"This code displays 6 images from the test set and their labels in a 2x3 grid. The label (class) information is added as a title for each image; if there is no label, \"Unknown Label\" is shown. This code is useful for visualizing the images in the test set and understanding which classes the model is predicting.","metadata":{}},{"cell_type":"code","source":"fit, ax = plt.subplots(nrows=2, ncols=3, figsize=(15, 8))\nax = ax.flatten()\nj = 0\nfor _ in range(6):\n    img, label = next(X_test_img) \n    ax[j].imshow(img[0].astype('uint8'))  \n\n    print(\"Label:\", label)  \n    if isinstance(label, np.ndarray) and label.size > 0:\n        ax[j].set_title(str(label[0]))  \n    else:\n        ax[j].set_title(\"Unknown Label\") \n\n    ax[j].axis('off')  \n    j += 1\n\nplt.tight_layout()  \nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:37.368127Z","iopub.execute_input":"2024-10-24T14:35:37.368552Z","iopub.status.idle":"2024-10-24T14:35:42.050071Z","shell.execute_reply.started":"2024-10-24T14:35:37.368504Z","shell.execute_reply":"2024-10-24T14:35:42.048920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We perform the following steps to examine the image dimensions and store them in a variable.\n\n","metadata":{}},{"cell_type":"code","source":"X_test_img[0][0].shape\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.051281Z","iopub.execute_input":"2024-10-24T14:35:42.051670Z","iopub.status.idle":"2024-10-24T14:35:42.451010Z","shell.execute_reply.started":"2024-10-24T14:35:42.051635Z","shell.execute_reply":"2024-10-24T14:35:42.450089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape=(256,256,3)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.452059Z","iopub.execute_input":"2024-10-24T14:35:42.452331Z","iopub.status.idle":"2024-10-24T14:35:42.456736Z","shell.execute_reply.started":"2024-10-24T14:35:42.452302Z","shell.execute_reply":"2024-10-24T14:35:42.455746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking Class Indices in the Training, Validation, and Test Sets\n","metadata":{}},{"cell_type":"code","source":"X_train_img.class_indices\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.457994Z","iopub.execute_input":"2024-10-24T14:35:42.458327Z","iopub.status.idle":"2024-10-24T14:35:42.469840Z","shell.execute_reply.started":"2024-10-24T14:35:42.458292Z","shell.execute_reply":"2024-10-24T14:35:42.469081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val_img.class_indices\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.471082Z","iopub.execute_input":"2024-10-24T14:35:42.471684Z","iopub.status.idle":"2024-10-24T14:35:42.481363Z","shell.execute_reply.started":"2024-10-24T14:35:42.471649Z","shell.execute_reply":"2024-10-24T14:35:42.480527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_img.class_indices\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.482473Z","iopub.execute_input":"2024-10-24T14:35:42.482762Z","iopub.status.idle":"2024-10-24T14:35:42.493623Z","shell.execute_reply.started":"2024-10-24T14:35:42.482733Z","shell.execute_reply":"2024-10-24T14:35:42.492755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CREATING THE MODEL**","metadata":{}},{"cell_type":"markdown","source":"**EVALUATING THE MODEL'S RESULTS**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=image_shape),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(9, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train_img,\n    epochs=10,\n    batch_size=32,\n    validation_data=(X_val_img,)\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:35:42.494787Z","iopub.execute_input":"2024-10-24T14:35:42.495162Z","iopub.status.idle":"2024-10-24T14:49:38.036628Z","shell.execute_reply.started":"2024-10-24T14:35:42.495121Z","shell.execute_reply":"2024-10-24T14:49:38.035839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:49:38.037914Z","iopub.execute_input":"2024-10-24T14:49:38.038228Z","iopub.status.idle":"2024-10-24T14:49:38.635188Z","shell.execute_reply.started":"2024-10-24T14:49:38.038189Z","shell.execute_reply":"2024-10-24T14:49:38.634019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_img)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = X_test_img.classes","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:49:38.636504Z","iopub.execute_input":"2024-10-24T14:49:38.636886Z","iopub.status.idle":"2024-10-24T14:50:07.343874Z","shell.execute_reply.started":"2024-10-24T14:49:38.636826Z","shell.execute_reply":"2024-10-24T14:50:07.343046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating Confusion Matrix ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n\ncm = confusion_matrix(y_true, y_pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:50:07.345060Z","iopub.execute_input":"2024-10-24T14:50:07.345393Z","iopub.status.idle":"2024-10-24T14:50:08.096520Z","shell.execute_reply.started":"2024-10-24T14:50:07.345357Z","shell.execute_reply":"2024-10-24T14:50:08.095612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classification Report","metadata":{}},{"cell_type":"markdown","source":"The classification Report is used to evaluate the performance of a classification model in detail. Metrics such as precision, recall, F1 score, and support allow us to understand which classes the model predicts well and which classes require further improvement. This information is critical for the development and enhancement of the model.\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_test_img)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = X_test_img.classes\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred_classes, \n                          target_names=X_test_img.class_indices.keys()))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T14:50:08.097746Z","iopub.execute_input":"2024-10-24T14:50:08.098071Z","iopub.status.idle":"2024-10-24T14:50:28.802309Z","shell.execute_reply.started":"2024-10-24T14:50:08.098037Z","shell.execute_reply":"2024-10-24T14:50:28.801324Z"},"trusted":true},"execution_count":null,"outputs":[]}]}